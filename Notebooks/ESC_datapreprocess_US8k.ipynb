{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1987065-b5cd-473d-93c4-15590a4f1dba",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Environmental Sound Classification</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed44716-eee1-431c-9b5a-b09a98f7c60d",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42c38fa-baef-42c7-8b50-87542b0a3ae7",
   "metadata": {},
   "source": [
    "Environmental Sound Classification: Develop a Python-based program that can classify different types of environmental sounds. The program should take audio files as input and predict the sound category (e.g., dog bark, car horn, rain, footsteps). The output should include the predicted class label and confidence score for each input sound. Optionally, visualize the waveform and spectrogram for better interpretability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53ad42d-d02e-48ec-9b16-d7ec41bbac09",
   "metadata": {},
   "source": [
    "### Dataset used: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176d1533-62a0-4cea-8336-c2e78367366e",
   "metadata": {},
   "source": [
    "This dataset contains 8732 labeled sound excerpts (<=4s) of urban sounds from 10 classes: air_conditioner, car_horn, children_playing, dog_bark, drilling, enginge_idling, gun_shot, jackhammer, siren, and street_music. The classes are drawn from the urban sound taxonomy. For a detailed description of the dataset and how it was compiled please refer to our paper.\n",
    "All excerpts are taken from field recordings uploaded to www.freesound.org. The files are pre-sorted into ten folds (folders named fold1-fold10) to help in the reproduction of and comparison with the automatic classification results reported in the article above.\n",
    "In addition to the sound excerpts, a CSV file containing metadata about each excerpt is also provided."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d63aa6-2c3e-419d-ac6e-60fc53cdccc5",
   "metadata": {},
   "source": [
    "### Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84fb6579-05e2-44ce-b015-a8b088a2ac91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c9b5ac-3167-4b7b-945d-729abc22f6b3",
   "metadata": {},
   "source": [
    "### Configs / Path Initialisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa5e7b17-9192-4eb8-99d7-76ebb4f6a7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_path= r\"E:\\Me\\coding\\jupyter\\Environmental_Sound_Classification\\dataset\\UrbanSound8K\\audio\"\n",
    "metadata_path= r\"E:\\Me\\coding\\jupyter\\Environmental_Sound_Classification\\dataset\\UrbanSound8K\\metadata\\UrbanSound8K.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f89e6e53-834f-45bd-8130-a4171d38c90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_PATH = \"fold_features\"\n",
    "os.makedirs(OUTPUT_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50b97d3a-31ef-48d4-ab60-54ad1ebd4801",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slice_file_name</th>\n",
       "      <th>fold</th>\n",
       "      <th>classID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100032-3-0-0.wav</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100263-2-0-117.wav</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100263-2-0-121.wav</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100263-2-0-126.wav</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100263-2-0-137.wav</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8727</th>\n",
       "      <td>99812-1-2-0.wav</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8728</th>\n",
       "      <td>99812-1-3-0.wav</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8729</th>\n",
       "      <td>99812-1-4-0.wav</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8730</th>\n",
       "      <td>99812-1-5-0.wav</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8731</th>\n",
       "      <td>99812-1-6-0.wav</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8732 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         slice_file_name  fold  classID\n",
       "0       100032-3-0-0.wav     5        3\n",
       "1     100263-2-0-117.wav     5        2\n",
       "2     100263-2-0-121.wav     5        2\n",
       "3     100263-2-0-126.wav     5        2\n",
       "4     100263-2-0-137.wav     5        2\n",
       "...                  ...   ...      ...\n",
       "8727     99812-1-2-0.wav     7        1\n",
       "8728     99812-1-3-0.wav     7        1\n",
       "8729     99812-1-4-0.wav     7        1\n",
       "8730     99812-1-5-0.wav     7        1\n",
       "8731     99812-1-6-0.wav     7        1\n",
       "\n",
       "[8732 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_df= pd.read_csv(metadata_path, usecols=[\"slice_file_name\", \"fold\", \"classID\"],dtype={\"fold\": \"uint8\", \"classID\" : \"uint8\"})\n",
    "metadata_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d488e13-83eb-4707-b1b9-9b6272da7428",
   "metadata": {},
   "source": [
    "### Data-Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf730ff-5a43-4d5d-85c3-c97b0b392a89",
   "metadata": {},
   "source": [
    "#### Using Mel-Frequency Cepstral Coefficients from Librosa:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c72287-77a6-41c7-ad27-8e03034f4a90",
   "metadata": {},
   "source": [
    "MFCC stands for Mel-frequency Cepstral Coefficients. It’s a feature used in automatic speech and speaker recognition. Essentially, it’s a way to represent the short-term power spectrum of a sound which helps machines understand and process human speech more effectively. Imagine your voice as a unique fingerprint. MFCCs, function similarly to a unique code capturing the salient features of your speech and enabling computers to discern between distinct words, and sounds. In speech recognition applications where computers must translate spoken words into text this code is especially helpful.[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8117cd52-da25-451c-8ae7-d3ecde048c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_mfcc(file_path, sr=22050, n_mfcc=120, max_len=173):\n",
    "    try:\n",
    "        y, sr = librosa.load(file_path, sr=sr)\n",
    "        mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
    "        mfcc = (mfcc - np.mean(mfcc)) / np.std(mfcc)  # Standardization\n",
    "        \n",
    "        # Fix length (pad or truncate to max_len time steps)\n",
    "        if mfcc.shape[1] < max_len:\n",
    "            pad_width = max_len - mfcc.shape[1]\n",
    "            mfcc = np.pad(mfcc, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
    "        else:\n",
    "            mfcc = mfcc[:, :max_len]\n",
    "        \n",
    "        # Flatten to 1D vector\n",
    "        return mfcc.flatten()\n",
    "    except Exception as e:\n",
    "        print(\"Error processing\", file_path, e)\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20caa8fc-4827-4a8e-8a48-f256c2e079c7",
   "metadata": {},
   "source": [
    "#### Using predefined 10-Fold as guided in the dataset [1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97bbdbc2-0b7f-4c8d-8d96-4339afdb1ae2",
   "metadata": {},
   "source": [
    "To ensure valid and comparable results when using the UrbanSound8K dataset, it is essential to follow the official 10-fold cross-validation protocol without reshuffling the data. Using the predefined folds prevents data leakage caused by placing related samples in both training and testing sets, which can falsely inflate model performance. Additionally, evaluating on all 10 folds (not just one) and averaging the results is crucial, as individual folds vary in difficulty. This approach aligns your results with prior research and ensures accurate performance assessment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "341e6ebf-00ee-4779-9b5b-2d64271e024c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Fold 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 824/873 [00:09<00:00, 127.42it/s]C:\\Users\\krjig\\AppData\\Roaming\\Python\\Python310\\site-packages\\librosa\\core\\spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=1103\n",
      "  warnings.warn(\n",
      "C:\\Users\\krjig\\AppData\\Roaming\\Python\\Python310\\site-packages\\librosa\\core\\spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=1323\n",
      "  warnings.warn(\n",
      "C:\\Users\\krjig\\AppData\\Roaming\\Python\\Python310\\site-packages\\librosa\\core\\spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=1523\n",
      "  warnings.warn(\n",
      "100%|██████████| 873/873 [00:10<00:00, 85.08it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Fold 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 888/888 [00:07<00:00, 119.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Fold 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 925/925 [00:07<00:00, 120.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Fold 4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 990/990 [00:09<00:00, 108.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Fold 5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 936/936 [00:08<00:00, 114.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Fold 6...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 823/823 [00:07<00:00, 116.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Fold 7...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 838/838 [00:07<00:00, 110.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Fold 8...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 806/806 [00:07<00:00, 111.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Fold 9...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 816/816 [00:07<00:00, 113.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Fold 10...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 837/837 [00:07<00:00, 114.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Preprocessing completed and saved fold-wise.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load metadata\n",
    "metadata = pd.read_csv(metadata_path)\n",
    "\n",
    "# Process each fold\n",
    "for fold in range(1, 11):\n",
    "    fold_df = metadata[metadata['fold'] == fold]\n",
    "    X, y = [], []\n",
    "\n",
    "    print(f\"Processing Fold {fold}...\")\n",
    "\n",
    "    for _, row in tqdm(fold_df.iterrows(), total=len(fold_df)):\n",
    "        filepath = os.path.join(audio_path, f\"fold{fold}\", row[\"slice_file_name\"])\n",
    "        label = row[\"classID\"]\n",
    "\n",
    "        features = extract_mfcc(filepath)\n",
    "        if features is not None:\n",
    "            X.append(features)\n",
    "            y.append(label)\n",
    "\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    np.save(os.path.join(OUTPUT_PATH, f\"X_fold{fold}.npy\"), X)\n",
    "    np.save(os.path.join(OUTPUT_PATH, f\"y_fold{fold}.npy\"), y)\n",
    "\n",
    "print(\"✅ Preprocessing completed and saved fold-wise.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78378097-7ead-470c-844e-021180072e05",
   "metadata": {},
   "source": [
    "### References:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff47f6c8-2ed3-4392-b7c8-da7904a8a3cc",
   "metadata": {},
   "source": [
    "1. J. Salamon, C. Jacoby and J. P. Bello, \"A Dataset and Taxonomy for Urban Sound Research\", 22nd ACM International Conference on Multimedia, Orlando USA, Nov. 2014.\n",
    "2. Sanjoy Barua, Tahmina Akter, Mahmud Abu Saleh Musa, Muhammad Anwarul Azim . A Deep Learning Approach for Urban Sound Classification. International Journal of Computer Applications. 185, 24 ( Jul 2023), 8-14. DOI=10.5120/ijca2023922991\n",
    "3. https://www.youtube.com/watch?v=mHPpCXqQd7Y\n",
    "4. https://www.geeksforgeeks.org/nlp/mel-frequency-cepstral-coefficients-mfcc-for-speech-recognition/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf50159-458c-4cf9-8a80-25530acf7650",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
